# Logistic regression {#sec-ch-logistic}

```{r}
#| include: false
source("_common.R")
```

## Learning goals {.unnumbered}

-   Identify whether linear or logistic regression is appropriate for a given analysis
-   Calculate and interpret probabilities, odds, and odds ratios
-   Interpret the coefficients of a logistic regression model
-   Conduct simulation-based and theory-based inference for the coefficients of a logistic regression model
-   Evaluate model conditions for logistic regression
-   Conduct logistic regression using R

<!-- ## R packages {.unnumbered} -->

```{=html}
<!--# 
-   `ggridges` [@ggridges]
-   `Hmisc` [@Hmisc-2]
-   `knitr` [@knitr-2]
-   `Stat2Data` [@Stat2Data-2]
-   `tidymodels` [@tidymodels-5]
-   `tidyverse` [@tidyverse-2]
-->
```

## Introduction: Comfort with driverless cars {#sec-logistic-intro-gss}

```{r}
#| echo: false

library(tidyverse)
library(tidymodels)
library(ggridges)
library(knitr)
library(Hmisc)
library(Stat2Data)
library(skimr)

# load gss data for 2024

gss24 <- gssr::gss_get_yr(2024)

# keep only respondents with answer to question about comfort with driverless car and make response variable

gss24_ai <- gss24 |>
  filter(!is.na(aidrive)) |>
  mutate(aidrive_comfort = factor(if_else(aidrive == 0, "0", "1")))


# prepare the predictor variables

gss24_ai <- gss24_ai |>
  filter(!is.na(aidrive),
         !is.na(age), 
         !is.na(sex)) |>
  mutate(sex = as_factor(sex), 
         income_fct = as_factor(case_when(
           income16 < 13 ~ "Less than $20k", 
           income16 >= 13 & income16 <= 18 ~ "$20-50k",
           income16 > 18 & income16 <= 22 ~ "$50-110k", 
           income16 > 22 ~ "$110k or more", 
           is.na(income16) ~ "Not reported")
         ),
         polviews_fct = as_factor(case_when(
           polviews %in% c(1, 2, 3) ~ "Liberal", 
           polviews == 4 ~ "Moderate", 
           polviews %in% c(5, 6, 7) ~ "Conservative",
           is.na(polviews) ~ "Not reported")), 
         tech_harm = as_factor(case_when(
           harmgood1 %in% c(1, 2) ~ "Agree",
           harmgood1 %in% c(4, 5) ~ "Disagree", 
           harmgood1 == 3 ~ "Neutral",
           TRUE ~ "Can't choose")),
         tech_easy = as_factor(case_when(
           techesy %in% c(1, 2) ~ "Agree", 
           techesy %in% c(4, 5) ~ "Disagree",
           techesy == 3 ~ "Neutral",
           TRUE ~ "Can't choose"
         ))
         ) |>
  mutate(income_fct = factor(income_fct, levels = 
                                c("Less than $20k", "$20-50k", "$50-110k", "$110k or more", "Not reported")), 
         polviews_fct = factor(polviews_fct, levels = 
                                 c("Moderate", "Liberal", "Conservative", "Not reported")),
         tech_harm = factor(tech_harm, levels = c("Neutral", "Can't choose", "Agree", "Disagree")), 
         tech_easy = factor(tech_easy, levels = c("Neutral", "Can't choose", "Agree", "Disagree")), 
         age = as.numeric(age) # get rid of the labels on age
         )

# main effects model
m <- glm(aidrive_comfort ~ sex + age + income_fct + tech_harm + tech_easy, data = gss24_ai, family = binomial)
```

Artificial Intelligence (AI) has quickly become ubiquitous, with generative AI tools such as ChatGPT being widely adopted in the workplace, school, and throughout every day life. One area in particular where AI is continuing to grow is in self-driving cars. The notion of riding in car that drives around as an individual reads a book has increasingly become a reality, with some cities already having self-driving taxis on the road. Waymo, a company that deploys a fleet self-driving taxis (called "robotaxis"), describes its robotaxi as "the world's most experienced driver." and is operating in five United States cities with plans to expand to two more at the time of this writing. ([waymo.com](https://waymo.com)). Additionally, Amazon has launched a robotaxi service in Las Vegas called Zoox [@Liedtke2025Zoox].

Despite the growth of self-driving cars, there are still complex moral questions [e.g., @Maxmen2018SelfDrivingCarEthics, @Vemoori2024EthicalDilemmasForbes] and the general readiness individuals have with this new technology and driving experience. David LI, co-founder of Hesai, a remote-sensing technology company, said that the adoption of self-driving cars are not just a question about technology development, but "it is a social question, it is a regulatory question, it is a political question" [@White2025HesaiSensors]. Therefore, it is important to understand how people, some of who may already will one day purchase a self-driving car, view this technological phenomenon.

::: {.objective latex=""}
The goal of the analysis in this chapter is to use data from the 2024 General Social Survey (GSS) to explore individual characteristics associated with one's comfort with self-driving cars.
:::

The GSS, administered by the National Science Foundation and is administered by National Opinion Research Center (NORC) at the University of Chicago, began in 1972 and is conducted about every two years to measure "trends in opinions, attitudes, and behaviors" among adults age 18 and older in the United States [@gss2024]. Households are randomly selected using multistage cluster sample based on data from the United States Census.

Respondents in the 2024 survey were part of the second year of an experiment studying survey administration and randomly split into two groups. The first group had the opportunity to complete the survey through an in-person interview (format traditionally used) and non-respondents were offered the online survey. The second group had the opportunity to take the online survey first, then non-respondents were offered the in-person interview. <!--# helpful to add response rate?-->

The data are in `gss24-ai.csv`. The data were obtained through the **gssr** R package [@gssr]. Questions about opinions on special topics such as technology are not given to every respondent, so the data in this analysis includes responses from `r nrow(gss24_ai)` adults who were asked about comfort with self-driving cars and who provided their age and sex in the survey. We will focus on the variables below (out of the over 600 variables in the full General Social Survey). The variable definitions are based on survey prompts and variable definitions in the *General Social Survey Documentation and Public Use File Codebook* [@gss2024].

**For the remainder of the chapter, we will refer to self-driving cars as "driverless cars" to align with the language used in the 2024 GSS.**

-   `aidrive_comfort`: Indicator variable for respondent's comfort with driverless (self-driving) cars. `0`: Not comfortable at all; `1`: At least some comfort.

    -   This variable was derived from responses to the original survey prompt: "Comfort with driverless cars". Scores ranged from 0 to 10 with 0 representing "totally uncomfortable with this situation" and 10 representing "totally comfortable with this situation". Responses of 0 on the original survey were coded as `aidrive_comfort = 0`. All other responses coded as 1.

-   `tech_easy` : Response to the question, "Does technology make our lives easier?" Categories are `Neutral`, `Can't choose` (Respondent doesn't know / is unable to provide an answer), `Agree`, `Disagree`.

-   `tech_harm`: Response to the question, "Does technology do more harm than good?". Categories are `Neutral`, `Can't choose` (Respondent doesn't know / is unable to provide an answer), `Agree`, `Disagree`.

-   `age`: Respondent's age in years

-   `sex`: Respondent's self-reported sex. Categories are `Male`, `Female`, the options provided on the original survey. <!--# see bayes rules for dealing with binary-->

-   `income`: Response to the question "In which of these groups did your total family income, from all sources, fall last year? That is, before taxes." Categories are `Less than $20k`, `$20-50k`, `$50-110k`, `$110k or more`, `Not reported` .

    -   Note: These categories were defined based on the 27 categories in `income16` from the original survey.

-   `polviews`: Response to the question, "I'm going to show you a seven-point scale on which the political views that people might hold are arranged from extremely liberal--point 1--to extremely conservative--point 7. Where would you place yourself?" Categories are `Moderate`, `Liberal`, `Conservative`, `No reported`.

    -   Note: These categories were defined based on the original 7 point scale.

::: {.analysis_in_practice latex=""}
The General Social Survey includes sample weights, so that the analysis data is representative of the population of adults in the United States.

These sample weights are not used in the analysis in this chapter or @sec-ch-logistic-prediction which uses the same data. Therefore, the analysis and conclusions we draw are only for educational purposes. To use the General Social Survey for research, see [@gss2024] for more information about incorporating the sample weights.
:::

### Exploratory data analysis

```{r}
#| label: fig-ai-comfort
#| fig-cap: Distribution of original and aggregated variable on comfort with driverless cars
#| fig-subcap: 
#|   - Distribution of original resposnes from 2024 GSS
#|   - Distribution of `aidrive_comfort`
#| layout-ncol: 2

ggplot(data = gss24_ai, aes(x = aidrive)) + 
  geom_bar(fill = "steelblue", color = "black") + 
  labs(x = "", 
       y = "Count") + 
  theme_bw()


ggplot(data = gss24_ai, aes(x = aidrive_comfort)) + 
    geom_bar(fill = "steelblue", color = "black") +
  labs(x = "", 
       y = "Count") + 
  theme_bw()
```

@fig-ai-comfort shows the distribution of the original responses to the survey question about comfort with driverless cars and `aidrive_comfort`, the binary variable we will use in the analysis. In practice, categorical variables may have many categories, so we can aggregate categories to simplify the variable based on the analysis question. We saw an example of this in @sec-univar-eda-cat when we looked at the variable `season` created from `month`. By simplifying the variable, we change the scope of the variable from a rating of the level of comfort an individual has with driverless cars to whether or not an individual has comfort with driverless cars. The latter aligns with the analysis objective and the modeling introduced in this chapter. Models for categorical response variables with three or more levels, such as the original survey responses, are introduced in @sec-multinomial.

```{r}
#| echo: false

p <- gss24_ai |>
  count(aidrive_comfort) |>
  mutate(p = n / sum(n)) |>
  filter(aidrive_comfort == 1) |>
  pull(p)
```

In @fig-ai-comfort-2, we see about `r round((1 - p) * 100,0)`% of the respondents said they were "totally uncomfortable" with driverless cars and `r round((p) * 100,0)`% reported some level of comfort with these cars. In the distribution of the original response variable in @fig-ai-comfort-1, among those who had at least some comfort, most had comfort levels of 5 or less. This detail could be important as we interpret the practical implications of the conclusions drawn from the analysis.

```{r}
#| label: fig-aidrive-predictor-eda
#| fig-cap: Univariate exploratory data analysis of predictor variables
#| fig-subcap: 
#|   - "`sex`"
#|   - "`age`"
#|   - "`tech_easy`"
#| layout-ncol: 2

ggplot(data = gss24_ai, aes(x = sex)) +
  geom_bar(fill = "steelblue", color = "black") +
  labs(x = "",
       y = "Count") +
  theme_bw() 
  

ggplot(data = gss24_ai, aes(x = age)) +
  geom_histogram(fill = "steelblue", color = "black", binwidth = 5) +
  labs(x = "",
       y = "Count") +
  theme_bw()

ggplot(data = gss24_ai, aes(x = tech_easy)) +
  geom_bar(fill = "steelblue", color = "black") +
  labs(x = "",
       y = "Count") +
  theme_bw()

```

```{r}
#| label: tbl-age-summary
#| tbl-cap: Summary statistics for `age`

gss24_ai |>
  skim(age) |>
  select(skim_variable, numeric.mean, numeric.sd, numeric.p0, 
         numeric.p25, numeric.p50, numeric.p75, numeric.p100, n_missing) |>
  kable(col.names = c("Variable", "Mean", "SD", "Min", "Q1", 
                      "Median (Q2)", "Q3", "Max","Missing"), 
        digits = 1)
```

@fig-aidrive-predictor-eda and @tbl-age-summary shows the univariate distributions of the predictor variables that will be used in this chapter. The exploratory data analysis for the other predictors is in @sec-ch-logistic-prediction <!--# reference specific section--> . The mean age in the data is about `r round(mean(gss24_ai$age), 1)` and the median is `r median(gss24_ai$age)` years old. The youngest respondents in the data set are `r min(gss24_ai$age)` and the oldest are `r max(gss24_ai$age)` years old. The standard deviation is about `r round(sd(gss24_ai$age), 3)` years, so the data spans the general age range for adults in the United States.

```{r}
#| echo: false


p_female <- gss24_ai |>
  count(sex) |>
  mutate(p = n / sum(n)) |>
  filter(sex == "female") |> 
  pull(p)

p_agree <- gss24_ai |>
  count(tech_easy) |>
  mutate(p = n / sum(n)) |>
  filter(tech_easy == "Agree") |> 
  pull(p)
```

We also observe from @fig-aidrive-predictor-eda that the majority of the respondents (about `r round(p_female * 100,0)` %) reported their sex as female, and a vast majority of respondents (about `r round(p_agree * 100,0)`%) agree that technology is making life easier.

```{r}
#| label: fig-aidrive-bivariate-eda
#| fig-cap: "Bivariate exploratory data analysis. Blue: `adrive_comfort = 0`, Red: `aidrive_comfort = 1`"
#| fig-subcap: 
#|   - "`aidrive_comfort` vs. `sex`"
#|   - "`aidrive_comfort` vs. `age`"
#|   - "`aidrive_comfort` vs. `tech_easy`"
#| layout-ncol: 2
#| echo: false

ggplot(data = gss24_ai, aes(x = sex, fill = aidrive_comfort)) +
  geom_bar(position = "fill", color = "black") +
  labs(x = "",
       y = "Proportion") +
  theme_bw() +
  scale_fill_manual(values = c("#1d457f", "#cc5c76"))

ggplot(data = gss24_ai, aes(x = age, y = aidrive_comfort, fill = aidrive_comfort)) +
  geom_density_ridges() + 
  labs(x = "",
       y = "") +
  theme_bw() +
  scale_fill_manual(values = c("#1d457f", "#cc5c76"))

ggplot(data = gss24_ai, aes(x = tech_easy, fill = aidrive_comfort)) +
  geom_bar(position = "fill", color = "black") +
  labs(x = "",
       y = "Proportion") +
  theme_bw() +
  scale_fill_manual(values = c("#1d457f", "#cc5c76"))
```

@fig-aidrive-bivariate-eda shows the relationship between the response and each of the predictor variables. Here we use a segmented bar plot <!--# is there a ref to EDA section?--> to visualize the relationship between the categorical predictors, `sex` and `tech_easy` and the categorical response, `aidrive_comfort`. As we look at the segmented bar plot, we are evaluating distribution of the response variable is approximately equal for each category of the predictor ([@sec-bivar-eda-cat-cat]). Unequal proportions suggests some relationship between the response and predictor variable. In @fig-aidrive-bivariate-eda, a higher proportion of males have comfort with driverless cars compared to the proportion of females. This indicates a potential relationship between sex and comfort with driverless cars. @fig-aidrive-bivariate-eda shows overlap in the distribution of age among those who have comfort with driverless cars versus those who do not, but the distribution among those who have comfort with driverless cars tends to skew younger. As with linear regression, however, we will use statistical inference [@sec-logistic-inf] to determine if the data provide evidence that such relationships exist.

::: {.yourturn latex=""}
Based on @fig-aidrive-bivariate-eda , does there appear to be a relationship between opinions about whether technology makes life easier and comfort with driverless cars? Explain.[^11-logistic-1]
:::

[^11-logistic-1]: There does appear to be some relationship. A higher proportion of those who agree technology makes life easier have comfort with driverless cars.

Now we use multivariate exploratory data analysis to explore potential interaction effects. Recall from @sec-mlr-interaction that an interaction effect occurs when the relationship between the response variable and a predictor differs based on values of the another predictor. We are often interested in interactions that include at least one categorical predictor, because we are interested how relationships might differ for subgroups in the sample.

<!--# Use boxplots, violin plots, density plots? -->

```{r}
#| label: fig-aidrive-interactions
#| fig-cap: "Mutlivariate EDA to explore potential interaction effects. Blue: `adrive_comfort = 0`, Red: `aidrive_comfort = 1`"
#| fig-subcap: 
#|   - "`aidrive` versus `age` faceted by `tech_easy`"
#|   - "`aidrive` versus `tech_easy` faceted by `sex`"
#| echo: false
#| layout-ncol: 2

ggplot(data = gss24_ai, aes(x = age, y = aidrive_comfort, fill = aidrive_comfort)) +
  geom_boxplot() + 
  labs(x = "Age in years",
       y = "") +
  theme_bw() + 
  facet_wrap(vars(tech_easy)) +
  scale_fill_manual(values = c("#1d457f", "#cc5c76"))


ggplot(data = gss24_ai, aes(x = tech_easy, fill = aidrive_comfort)) + 
  geom_bar(position = "fill", color = "black") + 
  labs(x = "",
       y = "Proportion") +
  theme_bw() + 
  facet_wrap(vars(sex)) +
  scale_fill_manual(values = c("#1d457f", "#cc5c76"))

```

@fig-aidrive-interactions-1 is the relationship between `age` and `aidrive_comfort` faceted by the categories of `tech_easy`. As we look at the four sets of boxplots, we observe whether the relationship of the boxplots is the same for each level of `tech_easy`. If so, this indicates the relationship between `age` and `aidrive_comfort` is the same regardless of the value of `tech_easy`. In @fig-aidrive-interactions-1, the relationship in the distributions of `age` between those who have comfort with driverless cars versus those who don't looks similar for the categories "Neutral", "Agree", and "Disagree". The boxes largely overlap and the median age is approximately the same between the two groups of `aidrive_comfort`. The relationship does appear to be different among those in the "Can't choose" category, as the median age among those who are not comfortable with driverless cars is higher than those who are comfortable.

@fig-aidrive-interactions-2 is a plot to explore the interaction between two categorical predictors `sex` and `tech_easy`. Similar as before, we are examining whether the relationship between `tech_easy` and `aidrive_comfort` differs based on `sex`. We are not looking to see whether the proportions are equal between the two groups but are instead looking to see whether the proportions are approximately equal relative to one another within each category of `sex`.

Using this as the criteria, the relationship between `tech_easy` and `aidrive_comfort` looks approximately equal for the categories of `sex`. Therefore, the data do not show evidence of an interaction between `tech_easy` and `sex`. We do note that in general, the proportion of males comfortable with driverless cars within each group of `tech_easy` is higher than the corresponding groups for females. This is expected, given what we observed in the bivariate EDA in @fig-aidrive-bivariate-eda.

## Probability / odds/ odds ratio {#sec-prob-odds}

### Probability and odds

<!--# The term "logistic regression" has not been introduced yet!-->

Before moving to modeling, let's take some time to focus on the response variable. The response variable $Y$ is categorical and takes values "0" or "1". The response $Y = 1$ indicates an observation takes the outcome of interest, and $Y = 0$ indicates an observation does not take that outcome. Sometimes $Y = 1$ and $Y = 0$ are called "success" and "failure", respectively. Note, however, that a "success" just means it is the outcome we are interested in studying, not necessarily what would be considered a "success" in practice.

The **probability** $Y=1$, denoted $Pr(Y=1)$, is a measure of the chance that the event $Y = 1$ occurs. Probabilities take values between 0 and 1, with 0 indicating an event is impossible and never occurs, and 1 indicating that an event always occurs. The **odds** $Y = 1$ are the ratio of the probability $Y = 1$ occurs versus the probability $Y = 0$ occurs. This is computed as

$$
\text{odds(Y = 1)} = \frac{Pr(Y = 1)}{Pr(Y = 0)} = \frac{Pr(Y = 1)}{1 - Pr(Y = 1)}
$$ {#eq-odds}

Note that the odds that $Y = 0$ are equal to $1/ \text{odds}(Y = 1)$ .

```{r}
#| label: tbl-response-prob-odds
#| tbl-cap: "Frequency, probability, and odds of `aidrive_comfort`"
#| echo: false

response_tbl <- gss24_ai |> 
  count(aidrive_comfort) |>
  mutate(probability = n / sum(n),
         odds = probability / (1 - probability)) 

response_tbl |>
  kable(digits = 3)

p <- response_tbl |> filter(aidrive_comfort == 1) |> pull(probability)

odds <- response_tbl |> filter(aidrive_comfort == 1) |> pull(odds)
```

@tbl-response-prob-odds shows the probabilities an odds for the response variable `aidrive_comfort`. In the data from `r nrow(gss24_ai)` respondents, the probability (chance) a randomly selected respondent is comfortable with driverless cars is `r round(p, 3)`. This may also be phrased as there is a `r round(p, 3) * 100` % chance a randomly selected respondent is comfortable with driverless cars. The odds a randomly selected respondent is comfortable with driverless cars are `r round(odds, 3)`. This means that a randomly selected respondent is `r round(odds, 3)` times more likely to be comfortable with driverless cars than not be.

::: {.yourturn latex=""}
Show how the following values are computed:

-   $Pr(\text{aidrive\_comfort} = 1) =$ `r round(p, 3)`

-   $\text{odds}(\text{aidrive\_comfort}=1)=$ `r round(odds, 3)` [^11-logistic-2]
:::

[^11-logistic-2]: $Pr(Y = 1) = 829 / (692 + 829) = 0.545$

    $\text{odds}(Y=1) = 0.545 / (1 - 0.545)  \approx 1.2$

    Note results differ slightly due to rounding.

### Odds ratio

We are most interested in understanding the relationship between comfort with driverless cars and other factors about the respondents. @tbl-aidrive-two-way is a **two-way** table of the relationship between `aidrive_comfort` and `tech_easy`. Now we can not only answer questions regarding opinions about comfort with driverless cars overall but can also see how these opinions on comfort may differ based on respondent's opinion about whether technology makes life easier.

<!--# do i move the your turn for probabilities and odds here?-->

```{r}
#| label: tbl-aidrive-two-way
#| tbl-cap: "Two-way table of `aidrive_comfort` (columns) versus `tech_easy` (rows)"

gss24_ai |>
  count(tech_easy, aidrive_comfort) |>
  pivot_wider(names_from = aidrive_comfort, 
              values_from = n) |>
  kable(col.names = c("Tech Easy", "0", "1"))
```

Each cell in the table is the number of observations that take the values indicated by the row and column. For example, there are 90 respondents in the data whose observed data are `tech_easy = "Neutral"` and `aidrive_comfort = "1"`. We can use this table to ask how the probability of being comfortable with driverless cars differs based on opinions about whether technology makes life easier. For example, we can compute the probability and the corresponding odds a randomly selected respondent is comfortable with driverless cars given they are neutral about whether technology makes life easier.

$$
\begin{aligned}
Pr(Y = 1| \text{tech\_easy = Neutral}) = \frac{90}{127 + 90}  \approx 0.415 \\[5pt]
\text{odds}(Y = 1| \text{tech\_easy = Neutral}) = \frac{90}{127} = \frac{0.415}{1 - 0.415}\approx{0.709}
\end{aligned}
$$ {#eq-prob-odds-cond}

$Pr(Y=1 | \text{tech\_easy = Neutral})$ is called a **conditional probability**, because it is the probability that a randomly selected respondent is comfortable with driverless cars conditioned on (given) they are neutral about whether technology makes life easier. Similarly, $\text{odds}(Y=1 | \text{tech\_easy = Neutral})$ are **conditional odds**.

::: {.analysis_in_practice latex=""}
It may sound awkward to communicate results where the odds are less than 1. Because the odds are reciprocal, they are typically reported in terms of the odds being greater than 1. For example, an alternative way to present the odds from @eq-prob-odds-cond is

> *A randomly selected respondent who is neutral about technology making life easier is `r round(1/0.709, 3)` times more likely to not be comfortable with driverless cars than be comfortable.*
:::

::: {.yourturn latex=""}
Compute the probability and corresponding odds of being comfortable with driverless cars among those who agree with the statement that technology makes life easier.[^11-logistic-3]
:::

[^11-logistic-3]: $Pr(Y=1 | \text{tech\_easy = Agree}) = 706/ (495 + 706) = 0.588$ and $\text{odds}(Y=1 | \text{tech\_easy = Agree)} = 0.588/(1 - 0.588) = 706/495 = 1.43$

From @tbl-aidrive-two-way, the odds a respondent who is neutral about technology making life easier is comfortable with driverless cars are 0.709, and the odds a respondent who agrees technology makes life easier are 1.43. We quantify how the odds for these two groups compare using an odds ratio. An **odds ratio** is computed as the odds for one group divided the odds for another, as shown in @eq-odds-ratio

$$
\text{odds ratio} = \frac{\text{odds}_{group 1}}{\text{odds}_{group 2}}
$$ {#eq-odds-ratio}

Let's compute the odds ratio for those who agree that technology makes life easier versus those who are neutral.

$$
\text{odds ratio} = \frac{\text{odds}_{\text{Agree}}}{\text{odds}_{\text{Neutral}}} = \frac{1.43}{0.709} = 2.02
$$

> This means that the odds a respondent who agrees technology makes life easier is comfortable with driverless cars are 2.02 times the odds a respondent who is neutral about technology is comfortable with driverless cars.

::: {.yourturn latex=""}
> Compute the odds ratio of being comfortable with driverless cars for `tech_easy = Agree` versus `teach_easy = Disagree`. Interpret this value in the context of the data.[^11-logistic-4]
:::

[^11-logistic-4]: The odds ratio is $\frac{706/495}{21/52} = 3.53$ . This means that the odds a respondent who agrees technology makes life easier is comfortable with driverless cars are 3.53 times the odds a respondent who is disagrees that technology is making life easier is comfortable with driverless cars.

<!--# do i want to cover this?-->

<!--# why odds over probabilities? -->

<!--# Some explanation about why we often prefer working with the odds vs. the probabilities? -->

<!--# Why look at odds ratios instead of probability ratio? Perhaps its just because of the model?-->

<!--# Suggestion from Chat GPT: odds multiply nicely -->

## From linear to logistic regression {#sec-logistic-model}

<!--# This needs to be reordered to be smoother between the why not linear and introducing logistic.-->

The two-way table and odds ratios from the previous section helped us being to explore the relationship between comfort with driverless cars and opinion about whether technology makes life easier. Let's build on this by fitting a model that can (1) help us quantify the relationship between variables, (2) explore the relationship between the response and multiple predictors variables, and (3) be used to make predictors and draw rigorous conclusions. Before diving into the details of this model's we'll take a moment to understand why we are introducing a new model for the relationship between `aidrive_comfort` versus the predictors rather than using the linear regression model we've seen up to this point.

<!--# your turn? - Identify the response variable in each scenario and whether it is quantitative or categorical.-->

<!--# do this using simulated data??-->

<!--# Intro of Hilbe logistic regression book has good explanation - reference that here.-->

Suppose we want to fit a model of the relationship between `age` and `aidrive_comfort`. Our first thought may be to use the linear regression model from @sec-ch-slr to model this relationship. In this case, the estimated model would be of the form

$$
\widehat{\text{aidrive\_comfort}} = \hat{\beta}_0 + \hat{\beta}_1 \times \text{age}
$$ {#eq-aidrive-age-linear}

```{r}
#| label: fig-try-linear
#| fig-cap: "Linear regression model for `aidrive_comfort` versus `age`"
#| echo: false

gss24_ai <- gss24_ai |>
  mutate(comfort_num = as.numeric(aidrive_comfort) - 1)

ggplot(data = gss24_ai, aes(x = age, y = comfort_num)) + 
  geom_point(alpha = 0.1, color = "black") + 
  geom_smooth(method = "lm", se = FALSE, color = "red") + 
  labs(x = "Age", 
       y = "Comfort with driverless cars") +
  theme_bw()
```

<!--# should I use jitter here instead?-->

@fig-try-linear is a visualization of the linear regression model for the relationship between `age` and `aidrive_comfort` shown in @eq-aidrive-age-linear. Here we easily see the linear regression model represented by the red line is not a good fit for the data. In fact, it (almost) never produces predictions of 0 or 1, the observed values of the response. Recall that the linear regression model is estimated by minimizing the sum of squared residuals, $0 - \hat{y}_i$ or $1 - \hat{y}_i$ in this scenario. These residuals can be minimized by finding a model that produces estimates between 0 and 1, as shown in @fig-try-linear, rather than trying to predict the actual observed values, 0 or 1.

Next, we might consider fitting a linear model such that the response variable is the $\pi = Pr(Y = 1)$, the probability of being comfortable with driverless cars. This estimated model takes the form

$$
\hat{\pi} = \hat{\beta}_0 + \hat{\beta}_1 \times \text{age}
$$ {#eq-aidrive-age-prob}

```{r}
#| label: fig-try-prob
#| fig-cap: "Linear model for Pr(`aidrive_comfort = 1`) versus `age`"
#| echo: false

comfort_age <- gss24_ai |>
  group_by(age) |>
  summarise(prob = mean(comfort_num)) |>
  ungroup()


ggplot(data = comfort_age, aes(x = age, y = prob)) + 
  geom_point(alpha = 0.3) + 
  geom_smooth(method = "lm", se = FALSE, color = "red") + 
  labs(x = "Age", 
       y = "P(Comfort with driverless cars)") +
  theme_bw()
```

@fig-try-prob shows the relationship between age and the probability of being comfortable with driverless cars. This model seems to be a better fit for the data, as it generally captures the trend that younger respondents are more likely to be comfortable with driverless cars compared to older respondents. The primary issue with using the probability as the response variable is that probabilities are bounded between 0 and 1. Therefore, it is impossible to get values less than 0 or greater than 1 in practice, so we would want the same bounded constraints on our model particularly if we wish to use the model for prediction. We saw a similar issue in @sec-ch-model-eval with the values of `valence` in the Spotify data. We have the same issue when using the odds as the response variable, because the odds cannot be less than 0. Therefore, we need a model that not only captures the relationship between the response and predictor but also addresses the boundary constraint.

When there is a binary categorical response variable, we use a **logistic regression model** to model the relationship between the binary response and one or more predictor variables as in @eq-logistic-model.

$$
\log\Big(\frac{\pi}{1 - \pi}\Big) = \beta_0 + \beta_1x_1 + \dots + \beta_px_p
$$ {#eq-logistic-model}

where $\pi = Pr(Y = 1)$ and $\log\big(\frac{\pi}{1 - \pi}\big)$ is the **logit transformation**, also called the "log odds". The log odds can take any value $-\infty$ to $\infty$, so it does not have the boundary constraints of the probability and odds. The log odds output from @eq-logistic-model can be transformed back to the odds and probabilities, and we will the probabilities to assign each observation to a predicted class `aidrive_comfort = 0` or `aidrive_comfort = 1`. We'll discuss this more in @sec-ch-logistic-prediction.

```{r}
#| label: fig-try-logistic
#| fig-cap: "Output from logistic regression model of `aidrive_comfort` versus `age`"

comfort_age <- comfort_age |>
  mutate(log_odds = log(prob/(1 - prob)))

ggplot(comfort_age, aes(x = age, y = log_odds)) +
  geom_point() +
  geom_smooth(method = "lm", color = "red", se = FALSE) +
  labs(x = "Age in years", 
       y = "logit(P(aidrive_comfort = 1))")
```

@fig-try-logistic shows the output of the logistic regression model of `aidrive_comfort` versus `age`. Here, we see the logit is not bounded as the probability or odds.

<!--# The red curve is the predicted logit from the logistic regression model. This curve is often referred to as the "S-curve", given its shape that resembles the English letter "S" as shown in the simulated data in @fig-logistic-curve-sim. From this visualization, we see the predicted probabilities are bounded between 0 and 1 as we would expect in practice, even though the logit can take any values between $-\infty$ to $\infty$.-->

::: {.math_rules latex=""}
@eq-logistic-model is the statistical model for logistic regression. The statistical model does not have the error term $\epsilon$ as we've seen in the statistical model for linear regression in @eq-mlr-stat-model-1. Recall from @sec-mlr-fit-line that the error term $\epsilon$ is the difference between the observed response $Y$ and the expected value produced by the model $\beta_0 + \beta_1x_1 + \dots + \beta_px_p$. Thus, we produce predictions for the response variable directly when doing linear regression.

<br>

In contrast, the output of the logistic regression model are the log odds that $y = 1$, not the actual observed values $y_i = 0$ or $y_i  = 1$. Thus, there is no error term in the statistical model for logistic regression, because we do not predict the value of the response directly and thus do not have the same notion of the difference between the observed and predicted response.
:::

## Interpreting model coefficients {#sec-logistic-interpret-coef}

<!--# make sure I actually talk about the likelihood function as promised in the model comparison chapter-->

In @sec-mlr-estimate-coef, we showed that the model coefficients for linear regression are estimated by the least-squares method, finding the values of the coefficients that minimizes the sum of squared residuals. There is no error term in the logistic regression model (see @eq-logistic-model-2), so we cannot use least-squares in this case. The model coefficients for logistic regression are estimated using **maximum likelihood estimation**. Recall from @sec-model-compare-stats that the likelihood is a function that quantifies how likely the observed data are to have occurred given a combination of coefficients. <!--# this definition is clunky.--> Thus, maximum likelihood estimation is used to find the combination of coefficients that makes the observed data the most likely to have occurred, i.e., that maximizes the value of the likelihood function. The mathematical details for estimating logistic regression coefficients using maximum likelihood estimation are available in @sec-logistic-estimation-matrix.

### Predictor in simple logistic regression

In @sec-prob-odds, we computed values from a two-way table to understand the relationship between opinions about whether technology makes life easier and comfort with driverless cars. Now we will use a logistic regression model to quantify the relationship.

```{r}
#| label: tbl-logistic-comfort-tech
#| tbl-cap: "Logistic regression model for `aidrive_comfort` versus `tech_easy`"
#| echo: false

comfort_tech_fit <- glm(aidrive_comfort ~ tech_easy,
                          data = gss24_ai, 
                          family = "binomial")

tidy(comfort_tech_fit) |> 
  kable(digits = 3)

```

@eq-logistic-comfort-tech is the equation from the model output in @tbl-logistic-comfort-tech.

$$
\begin{aligned}
\log\Big(\frac{\hat{\pi}}{1 - \hat{\pi}}\Big) = -0.344 + -0.061 \times \text{Can't choose}  + 0.699 \times \text{Agree}   - 0.562 \times \text{Disagree}
\end{aligned}
$$ {#eq-logistic-comfort-tech}

where $\hat{\pi}$ is the predicted probability a respondent is comfortable with driverless cars.

::: {.yourturn latex=""}
What is the baseline level for `tech_easy`? [^11-logistic-5]
:::

[^11-logistic-5]: The baseline level is `Neutral` . It is the only level that is not in the model output.

The intercept, -0.344, is the estimated log odds for respondents in the baseline group, `Neutral`. Similar to interpretations in @sec-transform-logy, though we do calculations using the logit, we write interpretations in terms of the odds, so they are more clearly understood by the reader. To transform from logit to odds, we exponentiate both sides of the model equation. @eq-logistic-comfort-tech-exp shows the equation from @tbl-logistic-comfort-tech in terms of the odds of being comfortable with driverless cars.

$$
\begin{aligned}
\frac{\hat{\pi}}{1 - \hat{\pi}} = e^{-0.344} \times e^{-0.061 \times \text{Can't choose}} \times e^{0.699 \times \text{Agree}}  \times e^{-0.562 \times \text{Disagree}}
\end{aligned}
$$ {#eq-logistic-comfort-tech-exp}

From @eq-logistic-comfort-tech-exp, we see that the estimated odds a respondent who is neutral about whether technology makes life easier is comfortable with driverless cars is `r round(exp(-0.344), 3)` ( $e^{-0.344}$). This equals the odds that was computed from the two-way table in @eq-prob-odds-cond.

::: {.math_rules latex=""}
The following two rules were used to go from @eq-logistic-comfort-tech to @eq-logistic-comfort-tech-exp

-   $e^{\log(a)} = a$

-   $e^{a+b}  = e^a e^b$
:::

Now let's look at the coefficient for `Agree`, 0.699. Putting together what know about the response variable with what we've learned about interpreting coefficients for categorical predictors in @sec-mlr-interpret-categorical, this estimated coefficient means the following:

> *The log odds a respondent who agrees technology makes life easier is comfortable with driverless cars are expected to be 0.699 higher than the log odds of a respondent who is neutral about whether technology makes life easier.*

From @eq-logistic-comfort-tech-exp, the coefficient for `Agree` is $e^{0.699} \approx 2.012$. This means the following:

> *The **odds** a respondent who agrees technology makes life easier is comfortable with driverless cars are expected to be 2.012 (* $e^{0.699}$*) **times** the odds of a respondent who is neutral about whether technology makes life easier.*

The value 2.012 is equal to the odds ratio of `aidrive_comfort = 1` for `tech_easy = Agree` versus `tech_easy = Neutral`. It is the same (give or take rounding) as the odds ratio we computed from @tbl-aidrive-two-way. This tells us something important about the relationship between the odds ratio and model coefficients in a logistic regression model. When we fit a simple logistic regression model with one categorical predictor $X$ such that $\beta_k$ is the coefficient corresponding to the $k^{th}$ level of $X$, then $e^{\beta_k}$ is the odds ratio between the $k^{th}$ level and the baseline level.

### Categorical predictors

Now, we will fit a multiple logistic regression model and use `age` along with `tech_easy` as predictors `aidrive_comfort`.

```{r}
#| label: tbl-logistic-comfort-tech-age
#| tbl-cap: "Logistic regression model for `aidrive_comfort` versus `age` and `tech_easy`"
#| echo: false

comfort_tech_age_fit <- glm(aidrive_comfort ~ tech_easy + age,
                          data = gss24_ai, 
                          family = "binomial")

tidy(comfort_tech_age_fit) |> 
  kable(digits = 3)
```

Now that we have multiple predictors in @tbl-logistic-comfort-tech-age, the intercept is the predicted log odds of being comfortable with driverless cars for those who are neutral about technology making life easier and who are 0 years old. It would be impossible for a respondent to be 0 years old, so while the intercept is necessary to obtain the best fit model, its interpretation is not meaningful in practice. As with linear regression, we could use the centered values of `age` in the model if we wish to have an interpretable intercept.

The coefficient for `Agree` in this model is 0.678. It is but not equal to the coefficient for `Agree` in the previous model, because now the coefficient is computed after adjusting for `age`. The interpretation is similar as before, taking into account the fact that age is also in the model.

> *The log odds a respondent who agrees technology makes life easier is comfortable with driverless cars are expected to be 0.678 higher than the log odds of a respondent who is neutral about whether technology makes life easier, holding age constant.*

To write the interpretation in terms of the odds, we need to exponentiate both sides of the model equation as in the previous section. @eq-logistic-comfort-tech-age-exp shows the relationship between opinions about technology, age, and the odds of being comfortable with driverless cars.

$$
\begin{aligned}
\frac{\hat{\pi}}{1 - \hat{\pi}} = e^{0.420} \times e^{-0.118 \times \text{Can't choose}} \times e^{0.678 \times \text{Agree}}  \times e^{-0.499 \times \text{Disagree}} \times e^{-0.015 \times \text{age}}
\end{aligned}
$$ {#eq-logistic-comfort-tech-age-exp}

where $\hat{\pi}$ is the predicted probability a respondent is comfortable with driverless cars.

Based on @eq-logistic-comfort-tech-age-exp, the interpretation of the `Agree` in terms of the odds is the following:

> *The **odds** a respondent who agrees technology makes life easier is comfortable with driverless cars are expected to be 1.970 (* $e^{0.678}$*) **times** the odds of a respondent who is neutral about whether technology makes life easier, holding age constant.*

The value 1.970 ($e^{0.678}$) is the odds ratio of comfort with driverless cars between those who agree technology makes life easier and those who are neutral, after adjusting for age. When there are multiple predictor variables in the logistic regression model, $e^{\beta_j}$ where $\beta_j$ is the coefficient for the predictor is called the **adjusted odds ratio (AOR).**

::: {.yourturn latex=""}
Use the model from @tbl-logistic-comfort-tech-age. Assume `age` is held constant.

-   Interpret the coefficient of `Disagree` in terms of the log odds of being comfortable with driverless cars.
-   Interpret the coefficient of `Disagree` in terms of the odds of being comfortable with driverless cars.[^11-logistic-6]
:::

[^11-logistic-6]: The log odds a respondent who disagrees technology makes life easier is comfortable with driverless cars are expected to be 0.499 less than the log odds of a respondent who is neutral about whether technology makes life easier, holding age constant.

    The odds a respondent who disagrees technology makes life easier is comfortable with driverless cars are expected to be `r round(exp(-0.499), 3)` ($e^{-0.499}$) times the odds of a respondent who is neutral about whether technology makes life easier, holding age constant.\
    \
    Alternatively, we could write this in terms of an odds ratio greater than 1: The odds a respondent is neutral about whether technology makes life easier is comfortable with driverless cars are expected to be `r round(1/exp(-0.499), 3)` ($1/e^{-0.499}$) times the odds of a respondent who disagrees that technology makes life easier, holding age constant.

### Quantitative predictors

Similar to categorical predictors, we can use what we learned about interpreting quantitative predictors in linear regression models in @sec-mlr-interpret-quantitative as a starting point for interpretations for logistic regression. Let's look at the interpretation of the coefficient for `age` from the model in @tbl-logistic-comfort-tech-age. The coefficient is the expected change in the response when the predictor increases by one unit . Given this, the interpretation for `age` in terms of the log odds is the following:

> *For each additional year increase in age, the log odds a respondent is comfortable with driverless cars are expected to decrease by 0.015, holding opinions about technology constant.*

Let's take a moment to show this interpretation mathematically by comparing the log odds between `age` and `age + 1`, where `age+1` represents the one unit increase in `age`. The interpretations are written holding opinions about technology constant, so we can ignore this predictor when doing these calculations. We'll also ignore the intercept, because it is also the same regardless of the value of `age`. Let $\text{log odds (comfort | age)}$ be the log odds given some value `age` and $\text{log odds (comfort | age + 1)}$ be the log odds given the value `age + 1`.

Then, the change in the log odds is

$$
\begin{aligned}
\text{log odds (comfort | age + 1)}  - \text{log odds (comfort | age)} &= -0.015 \times ( \text{age} + 1) - (-  0.015 \times \text{age}) \\
& = -0.015 ( \text{age} + 1 - \text{age}) \\
& = -0.015 
\end{aligned}
$$ {#eq-age-interpret-log-odds}

From @eq-age-interpret-log-odds, $\text{log odds (comfort | age + 1)} = \text{log odds (comfort | age)} - 0.015$.

Now we'll interpret the coefficient of `age` in terms of the odds. Based on @eq-logistic-comfort-tech-age-exp, the interpretation of `age` in terms of the odds of being comfortable with driverless cars is the following:

> *For each additional year increase in age, the **odds** a respondent is comfortable with driverless cars are expected to **multiply** by `r round(exp(-0.015), 3)` (* $e^{-0.015}$*), holding opinions about technology constant.*

::: {.math_rules latex=""}
-   $\log(a) + \log(b) = \log(ab)$

<!-- -->

-   $\log(a) - \log(b) = \log(\frac{a}{b})$
:::

We can show the interpretation mathematically starting with the result from @eq-age-interpret-log-odds.

$$
\begin{aligned}
\text{log odds (comfort | age + 1)}  - \text{log odds (comfort | age)} &= -0.015 \\[8pt]
\Rightarrow \log\Bigg(\frac{\text{odds (comfort | age + 1)}}{\text{odds (comfort | age)}}\Bigg) & = -0.015 \\[8pt]
*\text{exponetiate both sides}* \\[8pt]
\Rightarrow \frac{\text{odds (comfort | age + 1)}}{\text{odds (comfort | age)}} & = e^{-0.015}
\end{aligned}
$$ {#eq-age-interpret-odds}

From @eq-age-interpret-odds, $\text{odds (comfort | age + 1)} = e^{-0.015} \times \text{odds (comfort | age)}$. The value $\frac{\text{odds (comfort | age + 1)}}{\text{odds (comfort | age)}}$ is the odds ratio of being comfortable with driverless cars between `age` versus `age + 1`. Thus, given $\beta_j$ is the coefficient for a quantitative predictor $X_j$, the value $e^{\beta_j}$ is the (adjusted) odds ratio between $X_j + 1$ and $X_j$.

::: {.yourturn latex=""}
Use the model in @tbl-logistic-comfort-tech-age. Assume opinions about technology are held constant.

-   How are the log odds of being comfortable with driverless cars expected to change when age increases by 5 years?

-   How are the odds of being comfortable with driverless cars expected to change when age increases by 5 years? [^11-logistic-7]
:::

[^11-logistic-7]: When age increases by 5, the log odds are expected to decrease by `r round(abs(-0.015 * 5), 3)` ($-0.015 \times 5$ ) . The odds are expected to multiply by `r round(exp(-0.015 * 5), 3)` ( $e^{-0.015 \times 5}$).

<!--# do i discuss marginal effects and the change in probability? -->

## Inference for a coefficient $\beta_j$ {#sec-logistic-inf}

Inference for coefficients in logistic regression is very similar to inference in linear regression, introduced in @sec-ch-slr-inf and @sec-ch-mlr-inf. We will use these chapters as the foundation, discuss how they apply to logistic regression, and show ways in which inference for logistic regression differs. We refer the reader to the chapters on inference for linear regression for an introduction to statistical inference more generally.

### Simulation-based inference {#sec-logistic-sim-inf}

```{r}
#| label: logistic-permutation-code

set.seed(12345)

null_dist <- gss24_ai |> 
  specify(aidrive_comfort ~ tech_easy + age) |>
  hypothesize(null = "independence") |>
  generate(reps = 1000, type = "permute", variables = age) |>
  fit()

obs_fit <- gss24_ai |> 
  specify(aidrive_comfort ~ tech_easy + age) |> 
  fit()

pval <- get_p_value(null_dist, obs_stat = obs_fit, direction = "two-sided")
```

We can use simulation-based inference to draw conclusions about the model coefficients in logistic regression. The process for constructing bootstrap confidence intervals and using permutation sampling for hypothesis tests are the same as in linear regression, with the difference being the type of model that is fit. Here we will show how they apply to logistic regression.

#### Permutation tests {.unnumbered}

Hypothesis tests is used to test a claim about a population parameter. In the case of logistic regression, we use hypothesis tests to evaluate whether there is evidence of a relationship between a given predictor and the log odds of the response variable. The hypotheses to test whether there is a relationship between predictor $X_j$ and the response, after adjusting for the other predictors are in @eq-logistic-hypotheses.

$$
\begin{aligned}
&H_0: \beta_j = 0 - \text{There is no relationship between }X_j\text{ and the response}\\
&H_a: \beta_j \neq 0 - \text{There is a relationship between }X_j\text{ and the response}
\end{aligned}
$$ {#eq-logistic-hypotheses}

The hypothesis test is conducted assuming the null hypothesis is true. When doing simulation-based inference, we use permutation sampling to generate the null distribution under this assumption. The process for permutation sampling is the same for logistic regression as with linear regression in @sec-slr-testing-sim. The values of the predictor of interest $X_j$ are permuted, such that the values are randomly assigned to each observation. There is no relationship between the permuted values of $X_j$ and the response variable. The logistic model is fit to each permuted sample, and the estimated coefficients $\hat{\beta}_j$ from the permuted samples make up the null distribution. The null distribution is used to compute the p-value and draw a conclusion about the hypotheses.

We'll use a permutation test to evaluate whether there is evidence of a relationship between `age` and `aidrive_comfort` , after adjusting for `tech_easy`. <!--# be consistent with hypotheses in MLR inf chapter - do I include( adjusting fo rtech?)-->

$$
\begin{aligned}
H_0: \beta_{\text{age}} = 0 \hspace{2mm} \text{ vs } \hspace{2mm} \beta_{\text{age}} \neq 0
\end{aligned}
$$

The original value and five permutations of `age` for the first respondent are shown @tbl-logistic-permute.

```{r}
#| label: tbl-logistic-permute
#| tbl-cap: "Five permutations of `age` for Respondent 1"

set.seed(12345) 

niter = 1000 

permute_samp <- gss24_ai |> 
  specify(aidrive_comfort ~ tech_easy + age) |> 
  hypothesize(null = "independence") |>
  generate(reps = niter, type = "permute", variables = age) 

permute_samp1 <- permute_samp |> 
  group_by(replicate) |> 
  slice(1) |>
  ungroup() |> 
  slice(1:5)

respondent1 <- gss24_ai |> 
  slice(1)  |> 
  select(aidrive_comfort, tech_easy, age) |> 
  bind_rows(permute_samp1 |> select(-replicate)) 

respondent1 <- as.data.frame(respondent1)

row.names(respondent1) <- c("Original Sample", "Permutation 1", "Permutation 2", "Permutation 3", "Permutation 4", "Permutation 5")

respondent1 |> 
  kable(digits = 3)
```

@tbl-logistic-permute illustrates permutation sampling for one respondent. For each permutation, the value of `aidrive_comfort` and `tech_easy` are the same, and the values of `age` are randomly shuffled. <!--# do I use shuffled or assigned in previous chapters? Shuffled makes it clearer that these are values from the data set-->

@fig-logistic-permute is the null distribution produced from the 1000 permutations.

<!--# make sure this viz is consistent with MLR permutation-->

```{r}
#| label: fig-logistic-permute
#| fig-cap: "Null distribution produced by permutation sampling. The solid line is the observed value of `age`."

age_est <- obs_fit |>
  filter(term == "age") |>
  pull(estimate)

age_pval <- pval |> 
  filter(term == "age") |>
  pull(p_value)

null_dist |>
  ungroup() |>
  filter(term == "age") |>
  ggplot(aes(x = estimate))  +
  geom_histogram(fill = "darkcyan", color = "white") + 
  labs(x = "Estimated coefficient") +
  geom_vline(xintercept = age_est, color = "black", linetype = 1) +
 # geom_vline(xintercept = -age_est, color = "black", linetype = 2) +
  theme_bw()

```

@fig-logistic-permute shows that the estimated coefficient (solid vertical line) is far away from the center of the null distribution (the null hypothesized value 0), suggesting the evidence is not consistent with the null hypothesis. The p-value quantifies the strength of evidence against the null hypothesis. Based on the hypotheses in @eq-logistic-hypotheses, it is computed as the number of observations in the null distribution that have magnitude greater than $|\beta_{\text{age}}|$.

The p-value in this example is $\approx$ `r age_pval`. The p-value is very small, suggesting sufficient evidence against the null hypothesis. We reject the null hypothesis and conclude there is evidence of a relationship between age and comfort with driverless cars, after adjusting for opinions on technology.

#### Bootstrap confidence intervals {.unnumbered}

A confidence interval is a range of values in which a population parameter may reasonably take. <!--# compare this def to previous chapters and make sure its not plagarized-->This range of values is computed based on the sampling distribution of the estimated statistic. When conducting simulation-based inference, we use bootstrap sampling to construct this sampling distribution.

The process for constructing the sampling distribution using bootstrapping is the same for logistic regression as the process for linear regression in @sec-bootstrap-ci. Each bootstrap sample is constructed by sampling with replacement $n$ times, where $n$ is the number of observations in the sample data. The model is fit to each bootstrap sample, and the estimated coefficients make up the sampling distribution. The $C\%$ confidence interval is computed as the bounds marking the middle $C\%$ of the bootstrapped sampling distribution.

@fig-logistic-boot-dist is the bootstrap sampling distribution for $\hat{\beta}_{\text{age}}$ for 1000 bootstrap samples.

```{r}
#| label: logistic-bootstrap-code

set.seed(12345)

boot_dist <- gss24_ai |>
  specify(aidrive_comfort ~ tech_easy + age) |>
  generate(reps = 1000, type = "bootstrap") |>
  fit()

ci <- get_confidence_interval(
    boot_dist, 
    level = .95, 
    point_estimate = obs_fit
  )
```

```{r}
#| label: fig-logistic-boot-dist 
#| fig-cap: "Bootstrap distribution for the coefficient of `age`. The vertical lines are the bounds for the 95% confidence interval."

boot_age <- boot_dist |>
  filter(term == "age") |>
  ungroup()

ci_age <- ci |>
  filter(term == "age")

ggplot(data = boot_age, aes(x = estimate)) + 
  geom_histogram(fill = "darkcyan", color = "white") + 
  geom_vline(xintercept = ci_age$lower_ci, color = "black", linetype = 2) +
  geom_vline(xintercept = ci_age$upper_ci, color = "black", linetype = 2) +
  labs(x = "Estimated coefficient") +
  theme_bw()
```

The 95% bootstrap confidence is `r round(ci_age$lower_ci, 3)` to `r round(ci_age$upper_ci, 3)`. These values are marked by vertical lines in @fig-logistic-boot-dist. As with the model output, these are in terms of the relationship between age and the log odds of being comfortable with driverless cars. Thus, the direct interpretation of the 95% confidence interval is as follows:

> *We are 95% confident that for each additional year in age, the log odds of being comfortable with driverless cars decrease between `r abs(round(ci_age$upper_ci, 3))` to `r round(abs(ci_age$lower_ci), 3)`, holding opinions on technology constant.*

The interpretation in terms of the odds is the following:

> *We are 95% confident that for each additional year in age, the odds of being comfortable with driverless cars multiply by a factor of `r round(exp(ci_age$lower_ci), 3)` (* $e^{-0.021}$*) to `r round(exp(ci_age$upper_ci), 3)` (* $e^{-0.009}$ *), holding opinions on technology constant.*

### Theory-based inference {#sec-logistic-inf-theory}

The general process for theory-based inference for a single coefficient in logistic regression is similar as linear regression. The primary difference is in the distribution of the estimated coefficient $\hat{\beta}_j$.

When fitting a linear regression model, we have an formula for the estimated coefficients (see @sec-slr-estimation and @sec-mlr-estimate-coef). Thus we have an exact formula for the distribution of a given coefficient $\hat{\beta}_j$ that applies for any sample size. Recall that we account for the sample size in how we define degrees of freedom of the $t$ distribution for the coefficients (see @sec-mlr-inf-foundation).

In logistic regression, the coefficients are estimated using maximum likelihood estimation (see @sec-logistic-interpret-coef), such that numerical optimization methods are used to find the combination of coefficients that maximize the likelihood function. There is no closed-form equation for the estimated coefficients as with linear regression. Because the estimated coefficients are approximated using optimization, the distribution of the coefficients are also approximated.

When the sample size is large <!--# figure out reference for what large is-->, the distribution of the individual estimated coefficient $\hat{\beta}_j$ is $N(\beta_j, SE_{\hat{\beta}_j})$, approximately normal with an expected value of $\beta_j$, the true value of the coefficient and standard error $SE_{\hat{\beta}_j}$. In practice, we will get the estimated standard error from the software output. Mathematical details about computing $SE_{\hat{\beta}_j}$ are described in @sec-logistic-inference-matrix.

#### Hypothesis test {.unnumbered}

The steps for the hypotheses test are the same as those outlined in @sec-mlr-hypothesis-test.

1.  State the null and alternative hypotheses.
2.  Calculate a test statistic.
3.  Calculate a p-value.
4.  Draw a conclusion.

The hypotheses for a single coefficient are the same as in @eq-logistic-hypotheses:

$$
H_0: \beta_j = 0 \hspace{2mm} \text{ vs }\hspace{2mm} H_a: \beta_j \neq 0
$$

The test statistic, in @eq-logistic-test-stat, is called the Wald test statistic [@wald1943tests], <!--# make sure this is the correct reference-->because it is based on the approximation of the mean and standard error as $n$ is large.

$$
z = \frac{\hat{\beta}_j - 0}{SE_{\hat{\beta}_j}}
$$ {#eq-logistic-test-stat}

The test statistic, denoted by $z$, is the number of standard errors the estimated coefficient $\hat{\beta}_j$ is from 0, the hypothesized mean of the distribution. It follows a standard normal distribution, $N(0, 1)$, because it is based on asymptotic results (compared to the $t$ test statistic in linear regression which applies even for small $n$). Because the alternative hypothesis is two-sided, the p-value is computed as $P(|Z| \geq |z|)$ , where $Z \sim N(0, 1)$. <!--# did i do > or >= in linear regression?--> The p-value is interpreted as before, with small p-values providing stronger evidence against the null hypothesis.

Let's take a look at the hypothesis test for the coefficient of `age` using the theory-based methods. The components for the theory-based hypothesis test are produced in the model output. The output of the model including `tech_easy` and `age` is reproduced in @tbl-comfort-tech-age-2 along with the 95% confidence intervals for the model coefficients.

```{r}
#| label: tbl-comfort-tech-age-2
#| tbl-cap: "Model output for `aidrive_comfort` versus `tech_easy` and `age` with 95% confidence intervals for coefficients"


tidy(comfort_tech_age_fit, conf.int = TRUE) |>
  kable(digits = 3)

```

The hypotheses are the same as with simulation-based inference

$$
H_0:\beta_{\text{age}} = 0 \hspace{2mm} \text{ vs }\hspace{2mm} \beta_{\text{age}} \neq 0
$$

The null hypothesis is that there is no relationship between age and comfort with driverless cars after accounting for opinions about technology. The alternative hypothesis is that there is a relationship.

The test statistic[^11-logistic-8] is computed as

[^11-logistic-8]: Note the difference the result here and the model output is because the model output is computed using exact values of $\hat{\beta}_j$ and $SE_{\hat{\beta}_j}$.

$$
z = \frac{-0.015 - 0}{0.003} \approx - 5 
$$

The p-value is computed as $P(|Z| \geq |-4.902|) \approx$ `r 2 * dnorm(-4.902, 0, 1)`. This value is so small it rounds to 0 when displaying the results to 3 digits. This is consistent with the p-value we observed from the permutation test in @sec-logistic-sim-inf. Because the p-value is small, we reject the null hypothesis and conclude there is evidence of a relationship between age and comfort with driverless cars after adjusting for opinions about technology.

::: {.analysis_in_practice latex=""}
We can use a decision-making threshold $\alpha$ when using the p-value to draw conclusions from a hypothesis test. The potential for Type I and Type II errors is the same for logistic regression as in linear regression. See @sec-slr-inf-conclusion for more on choosing $\alpha$ and potential errors.
:::

#### Confidence interval {.unnumbered}

The equation to compute the confidence interval for coefficients in logistic regression is very similar to the formula in linear regression from @sec-slr-inf-clt. The difference is the critical value $z^*$ is computed from the $N(0, 1)$ distribution

$$
\hat{\beta}_j \pm z^* \times SE_{\hat{\beta}_j}
$$ {#eq-logistic-theory-ci}

In practice, the confidence interval is produced in the model output. Let's show how the 95% confidence interval for `age` is computed in @tbl-comfort-tech-age-2.

The values for $\hat{\beta}_j$ and $SE_{\hat{\beta}_j}$ can be read directly from table, as before. The critical value $z^*$ is the point on the $N(0, 1)$ distribution such that the middle 95% (or $C\%$ in general) of the distribution is between $-z^*$ and $z^*$. We can use statistical software to get this value as shown in @sec-logistic-r. The $z^*$ for the 95% confidence interval is `r round(qnorm(0.975, 0, 1), 3)`.

The 95% confidence interval for the coefficient of `age` is

$$
\begin{aligned}
&-0.015 \pm 1.96 \times 0.003 \\[5pt]
\Rightarrow &-0.015 \pm  0.00588 \\[5pt]
\Rightarrow &\mathbf{[ -0.021 , -0.009]}  
\end{aligned}
$$

::: {.yourturn latex=""}
-   Interpret this interval in the context of the data in terms of the odds of being comfortable with driverless cars.
-   How does this interval compare to the bootstrap confidence interval computed in @sec-logistic-sim-inf? [^11-logistic-9]
:::

[^11-logistic-9]: We are 95% confident that for each additional year in age, the odds of being comfortable with driverless cars are expected to multiply by `r round(exp(-.021), 3)` ( $e^{-0.021}$ ) to `r round(exp(-.009), 3)` ( $e^{-0.009}$), holding opinions about technology constant. This interval is equal to the interval obtained using bootstrapping.

#### Connection between hypothesis test and confidence intervals {.unnumbered}

The same connection between two-sided hypothesis tests and confidence intervals applies in the context of logistic regression as we saw in linear regression in @sec-slr-inf-relationship-ci-test . A two-sided hypothesis test with decision-making threshold of $\alpha$ directly corresponds to the $(1 - \alpha) \times 100 \%$ confidence interval. For example, a hypothesis test with decision-making threshold of $\alpha = 0.05$ directly corresponds to the 95% ($(1 - 0.05) \times 100$) confidence interval.

This means we can use a confidence interval to evaluate a claim about a coefficient and get a range of values the population coefficient may take. The following are the relationship between the confidence interval and hypothesis test:

-   Confidence interval for $\beta_j$ : If 0 is in the interval, fail to reject the null hypothesis. If 0 is not in the interval, reject the null hypothesis.

-   Confidence interval for $e^{\beta_j}$: If 1 is in the interval, fail to reject the null hypothesis. If 1 is not in the interval, reject the null hypothesis.

::: {.yourturn latex=""}
Use the output in @tbl-comfort-tech-age-2.

-   Show how the test statistic is computed for `tech_easyDisagree`. Interpret this value in the context of the data.
-   Do the data provide evidence that the odds are different among those who disagree technology makes life easier compared to those who are neutral (the baseline), after adjusting for age? Use $\alpha = 0.05$ Explain.
-   Show how the 95% confidence interval for `tech_easyDisagree` is computed. Is it consistent with your conclusion in the previous question?[^11-logistic-10]
:::

[^11-logistic-10]:
    -   The test statistic is $\frac{-0.499 - 0}{0.295} \approx - 1.69$. The estimated coefficient of -0.499 is 1.69 standard errors below the hypothesized mean of 0. The p-value 0.091 \> 0.05, so the data do not provide sufficient evidence the odds are different for those who disagree that technology makes life easier versus those who are neutral, after adjusting for age. The 95% confidence interval is computed as $-0.499 \pm 1.96 \times 0.295$. It is consistent with the conclusion, because 0 is in the interval.\

<!--# Inference for a subset of coefficients  -->

<!--# Make this section brief and refer to Roback and Hilbe for more information about this.-->

## Model conditions {#sec-logistic-conditions}

<!--# model conditions or assumptions?-->

We fit logistic regression model under a set of assumptions. These are similar to the assumptions for linear regression in @sec-slr-foundation, but there is no assumption related to normality or equal variance.

1.  There is a linear relationship between the predictors and logit of the response variable
2.  The observations are independent of one another <!--# use same wording as linear regression-->

Similar to linear regression, we check model conditions to evaluate whether these assumptions hold for the data.

### Linearity

The linearity assumption for logistic regression states that there is a linear relationship between the predictors and the logit of the response variable. We check this assumption by looking at plots of the quantitative predictors versus the empirical logit of the response. The **empirical logit** is the log-odds of a binary variable ("logit") calculated from the data ("empirical"). For example, @eq-emp-logit is the empirical logit for the comfort with driverless cars in the sample data set.

$$
\text{empirical logit} = \log\Big(\frac{\pi}{1 - \pi}\Big) = \log\Big(\frac{0.545}{1 - 0.545}\Big) = 0.180
$$ {#eq-emp-logit}

We can also look at the empirical logit by subgroup of a categorical variable. For example, @tbl-emp-logit-tech shows the empirical logit by opinion on whether technology makes life easier.

```{r}
#| label: tbl-emp-logit-tech
#| tbl-cap: "Probability and empirical logit of `aidrive_comfort` by `tech_easy`"

gss24_ai |> 
  group_by(tech_easy) |>
  count(aidrive_comfort) |>
  mutate(Probability = n / sum(n)) |>
  mutate(`Empirical Logit` = log(Probability/(1 - Probability))) |>
  mutate(n = sum(n)) |>
  filter(aidrive_comfort == 1) |>
  select(tech_easy,n,Probability, `Empirical Logit`) |>
  kable(digits = 3)

```

Computing the empirical logit across values of a quantitative predictor is similar as the process for categorical predictors. We divide the values of the quantitative predictor into bins and compute the empirical logit of the response for the observations within each bin. There are multiple ways to divide the quantitative predictor into bins. Some software creates the bins, such that there are an equal number of observations in each bin. Another option is to create bins by dividing by some incremental amount (e.g., dividing `age` into 5 or 10 year increments). Dividing the variable by the same incremental amount can be more easily interpreted; however, there may be large variation in the number of observations in each bin that needs to be taken into account when comparing the empirical logit across bins. The former method may be less interpretable, but we know the empirical logit is computed using the same observations for each bin.

@tbl-emp-logit-age shows the number of observations $n$, probability, and empirical logit across bins of `age` using the two approaches for dividing `age` into bins. In Table (a) of @tbl-emp-logit-age, the bins have been created such that the observations are more evenly distributed across bins. Often, the number of observations will be equal or differ by a small amount. In this case, because `age` is a discrete variable, there are many observations with the exact same value of age. For example, there are `r gss24_ai |> filter(age == 39) |> nrow()` observations with the age of 39 years old. Because all observations with the same age are in the same bin, the number of observations in bins that include ages that occur frequently is higher than less common ages in the data, such as those over 70 years old. Note, however, that the number of observations in each bin are still more even than when the bins are created using equal age increments.

```{r}
#| label: tbl-emp-logit-age
#| tbl-cap: "Probability and empirical logit of `aidrive_comfort` by `age`"
#| tbl-subcap:
#|   - "Evenly distribute observations" 
#|   - "Equal age increments"
#| layout-ncol: 2

# evenly distribute observations across bins
gss24_ai |> 
  mutate(age_bins = cut2(age, g = 10)) |> #from the Hmisc package - about equal observations in each bin
  group_by(age_bins) |>
  count(aidrive_comfort) |>
  mutate(Probability = n / sum(n)) |>
  mutate(`Empirical Logit` = log(Probability/(1 - Probability))) |>
  mutate(n = sum(n)) |>
  filter(aidrive_comfort == 1) |>
  select(age_bins, n, Probability, `Empirical Logit`) |>
  kable(digits = 3)

# equal age increments
gss24_ai |> 
  mutate(age_bins = cut(age, breaks = 10, dig.lab = 0)) |>
  group_by(age_bins) |>
  count(aidrive_comfort) |>
  mutate(Probability = n / sum(n)) |>
  mutate(`Empirical Logit` = log(Probability/(1 - Probability))) |>
  mutate(n = sum(n)) |>
  filter(aidrive_comfort == 1) |>
  select(age_bins,n, Probability, `Empirical Logit`) |>
  kable(digits = 3)
```

<!--# maybe format this different? get rid of probability column?-->

Now that we can compute the empirical logit, let's use it to check the linearity assumption. As with linear regression, we only check linearity for quantitative predictors. To check linearity, we will make a plot of the empirical logit of the response versus the bins of the quantitative predictor. We use the mean value within each bin of the predictor to represent the bin on the graph.

@fig-emp-logit-age shows a plot of the empirical logit of being comfortable with driverless cars versus the mean value of age in each bin. We use the bins from Table (a) in @tbl-emp-logit-age, so that we know there is a similar number of observations represented by each point on the graph.

```{r}
#| label: fig-emp-logit-age
#| fig-cap: "Empirical logit of `aidrive_comfort` versus `age`"

emplogit_age <- gss24_ai |> 
  mutate(age_bins = cut2(age, g = 10)) |> #from the Hmisc package - about equal observations in each bin
  group_by(age_bins) |>
  count(aidrive_comfort) |>
  mutate(Probability = n / sum(n)) |>
  mutate(emp_logit = log(Probability/(1 - Probability))) |>
  filter(aidrive_comfort == 1) 

mean_age  <- gss24_ai |> 
  mutate(age_bins = cut2(age, g = 10)) |> #from the Hmisc package - about equal observations in each bin
  group_by(age_bins) |>
  summarise(mean_age = mean(age))


emplogit_age |> 
  left_join(mean_age, by = "age_bins") |>
  ggplot(aes(x = mean_age, y = emp_logit)) +
  geom_point() +
  #geom_smooth(se = FALSE,  color = "red") +
  labs(x = "Mean age", 
       y = "Empirical logit of (aidrive_comfort = 1)") +
  theme_bw()
```

<!--# use the same format as the conditions from linear regression-->

When examining the plot of empirical logit versus the binned quantitative predictor, we are asking whether a line would reasonably describe the relationship between the predictor and empirical logit. The condition is satisfied if the trend generally looks linear overall. As with checking the linearity condition for linear regression, we are looking for obvious violations, not exact adherence to linearity.

From @fig-emp-logit-age, it appears there is a potential quadratic relationship between age and comfort with driverless cars, and thus the linearity condition **is not satisfied.** <!--# this seems like a strange conclusion. maybe reframe the purpose of the linearity condition.---> The empirical logit is lowest for respondents around 60 years old, then it appears to increase again. This prompts us to consider a quadratic term for the model.

```{r}
#| label: tbl-comfort-tech-age-sq
#| tbl-cap: Logistic regression model including quadratic term for age.


comfort_tech_age_sq_fit <- glm(aidrive_comfort ~ tech_easy + age + I(age^2),
                               data = gss24_ai, 
                               family = "binomial"
)

age_sq_lb <- tidy(comfort_tech_age_sq_fit, conf.int = TRUE) |>
  filter(term == "I(age^2)") |> 
  pull(conf.low)

age_sq_ub <- tidy(comfort_tech_age_sq_fit, conf.int = TRUE) |>
  filter(term == "I(age^2)") |> 
  pull(conf.high)

comfort_tech_age_sq_fit |> 
  tidy(conf.int = TRUE) |>
  kable(digits = 4)
```

<!--# is adding the quadratic term too much of a digression?-->

@tbl-comfort-tech-age-sq is the output of the model that includes the quadratic term for `age`. The p-value for the quadratic term is around 0.05, so based on this alone, it is unclear whether or not to keep the squared term in the model. Thus, let's look at the confidence interval and some model comparison statistics introduced in @sec-model-compare-stats to have more information to take into account regarding the quadratic term.

The 95% confidence interval for the coefficient of $\text{age}^2$ is `r age_sq_lb` to `r age_sq_ub`. This shows the quadratic term has a very small adjustment on the relationship between age and comfort with driverless cars. Even if the quadratic term is statistically significant, it may not be practically significant.

```{r}
#| label: tbl-age-sq-compare
#| tbl-cap: "AIC and BIC for models with and without quadratic term for `age`"

c("Age", "Age + Age^2") |>
bind_cols(glance(comfort_tech_age_fit) |> select(AIC, BIC) |>
  bind_rows(glance(comfort_tech_age_sq_fit) |> select(AIC, BIC))
) |>
  kable(digits = 3, col.names = c("Model", "AIC", "BIC"))
```

In @tbl-age-sq-compare, we look at the AIC and BIC for the model with and without the quadratic term for age. The model that includes $\text{age}^2$ has a lower AIC but a higher BIC. The difference in the AIC values is small, indicating that that one model is not preferenced over the other in terms of model fit. The same is true when comparing the values of BIC. Therefore, with a mind towards choosing the most parsimonious (simplest) model without hindering model performance, we choose to remove the quadratic term and move forward including only the main effect for `age`.

### Independence

The independence assumption for logistic regression is similar to the assumption for linear regression, that there are no dependencies between observations. As with linear regression, this assumption is important, because we conduct inference assuming we have $n$ pieces of independent information produced by the $n$ observations. If observations there is dependency between observations, then we are effectively working with less than $n$ pieces of independent information, as knowing something about one observation tells a lot about all the others that are correlated with it.

We typically evaluate independence based on a description of the observations and the data collection process. If there are potential dependency issues based on the order in which the data were collected, spatial correlation, or other sub group dependencies, we can use visualizations to plot the odds or empirical logit of the response by time, space, or subgroup, respectively. We can also add predictors in the model to account for those potential dependencies.

For this analysis on comfort with driverless cars, the independence condition is satisfied**.** Based on the description of the sample and data collection process in @sec-logistic-intro-gss, we can reasonably conclude there are no dependencies between respondents.

::: {.analysis_in_practice latex=""}
We conduct logistic regression assuming the data are a representative sample from the population of interest. Ideally, it would be a random sample, but that is not always feasible in practice. Therefore, even if the sample is not completely random, it should be representative of the population.

If there are biases in the sample (e.g., a particular subgroup is over or under represented in the data), they will influence the interpretations, conclusions, and predictions from the model. Therefore, we can narrow the scope of the population for the analysis, or clearly disclose these biases when presenting the results.

This issue often occurs in survey data, like the data we're analyzing in this chapter. Data scientists analyzing survey data will often include weights in their analysis so that the sample looks more representative of the population in the analysis calculations even if the original data has some bias. <!--# insert refs for weighted methods-->
:::

<!--# do i need to say anything about diagnostics and outliers? -->

<!--# From Chat GPT: Maybe mention perfect separation (this could be a callout box). Does this go in the next chapter about prediction?-->

## Logistic regression in R {#sec-logistic-r}

### Fitting a logistic model

The logistic regression model is fit using `glm()` in the **stats** package in base R. This function is used to fit a variety of models that are part of the wider class of models called generalized linear models, so we must also specify which generalized linear model is being fit when using this function. The argument `family = binomial` is specifies that the model fit is a logistic regression model.

```{r}
#| echo: true
comfort_tech_age_fit <- glm(aidrive_comfort ~ tech_easy + age,
                          data = gss24_ai, 
                          family = binomial)
```

We input the observed categorical response variable and R does all computations behind the scenes to produce the model in terms of the logit. The response variable must be coded as a character (`<chr>`) or factor (`<fct>`) type.

The `tidy` function produces the model output in a tidy form and `kable()` can be used to neatly format the results to a specific number of digits. The argument `conf.int = TRUE` shows the confidence interval, and `conf.level =` is used to set the confidence level.

```{r}
#| echo: true

tidy(comfort_tech_age_fit, conf.int = TRUE ,conf.level = 0.95) |>
  kable(digits = 3)
```

By default, the tidy function will show the model output for the response in terms of the logit. The argument `exponentiate = TRUE` will produce the output for the model in terms of the odds with the exponentiated coefficients. The argument, `exponentiate` is set to `FALSE` by default.

```{r}
#| echo: true

tidy(comfort_tech_age_fit, conf.int = TRUE ,conf.level = 0.95, 
     exponentiate = TRUE) |>
  kable(digits = 3)
```

### Simulation-based inference

The code for simulation-based inference is the same for logistic regression as the code for linear regression introduced in @sec-slr-R. Behind the scenes, the functions in the **infer** R package use the response variable to determine whether to fit a linear or logistic regression model.

Below is the code for the bootstrap confidence intervals and permutation test conducted in @sec-logistic-sim-inf. We refer the reader to @sec-mlr-sim-inf-R for more a more detailed explanation about the code.

**Permutation test**

```{r}
#| echo: true

# set seed
set.seed(12345)

# construct null distribution using permutation sampling
null_dist <- gss24_ai |> 
  specify(aidrive_comfort ~ tech_easy + age) |>
  hypothesize(null = "independence") |>
  generate(reps = 1000, type = "permute", variables = age) |>
  fit()

# compute observed coefficient
obs_fit <- gss24_ai |> 
  specify(aidrive_comfort ~ tech_easy + age) |> 
  fit()

# compute p-value
pval <- get_p_value(null_dist, obs_stat = obs_fit, direction = "two-sided")
```

**Bootstrap confidence interval**

```{r}
#| echo: true

# set seed
set.seed(12345)

# construct bootstrap distribution 
boot_dist <- gss24_ai |>
  specify(aidrive_comfort ~ tech_easy + age) |>
  generate(reps = 1000, type = "bootstrap") |>
  fit()

# compute confidence interval
ci <- get_confidence_interval(
    boot_dist, 
    level = 0.95, 
    point_estimate = obs_fit
  )
```

### Empirical logit plots

The code to compute the empirical logit primarily utilizes data wrangling functions in the **dplyr** R package [@dplyr].

**Empirical logit for groups of a categorical variable**

The code below produces the empirical logit for being comfortable with driverless cars for each level of `tech_easy`, opinion on whether technology makes life easier.

```{r}
#| echo: true

gss24_ai |>  # <1>
  group_by(tech_easy) |> # <2>
  count(aidrive_comfort) |> # <3>
  mutate(probability = n / sum(n), # <4>
         empirical_logit = log(probability/(1 - probability)))
```

1.  Use the `gss24_ai` data frame.
2.  Compute all subsequent calculations separately for each level of `tech_easy`.
3.  Count the number of observations such that `aidrive_comfort == 0`, and the number of observations such that `aidrive_comfort == 1`.
4.  Compute the probability that `aidrive_comfort == 0` and `aidrive_comfort == 1` .
5.  Compute the empirical logit that `aidrive_comfort == 0` and the empirical logit that `aidrive_comfort == 1` .

The code to compute the empirical logit based on a quantitative predictor is the similar, with the additional step of splitting the quantitative predictor into bins. There are many ways to do this in R; here we will show the functions used for the tables in @sec-logistic-conditions.

The first is using the `cut()` function that is part of base R. This function transforms numeric variable types into factor variable types by dividing them into bins. The argument `breaks =` is used to either specify the number of bins or explicitly define the bins. If the number of bins is specified, `cut()` will divide the observations into bins of equal length, as shown in the code below.

Once the bins are defined, the remainder of the code is the same as before, where the probability and empirical logit are computed for each bin. Here is the code to compute the empirical logit of comfort with driverless cars by age, where age is divided into 10 bins. Here, the `cut()` function divided the age into bins of length 7.

Note that the option `dig.lab = 0` in the `cut()` function means to display the bin thresholds as integers, i.e., with 0 digits. This only changes how the lower and upper bounds are displayed; it does not change any computations.

```{r}
#| echo: true

gss24_ai |> 
  mutate(age_bins = cut(age, breaks = 10, dig.lab = 0)) |>
  group_by(age_bins) |>
  count(aidrive_comfort) |>
  mutate(probability = n / sum(n)) |>
  mutate(empirical_logit = log(probability/(1 - probability))) 
```

Another option for splitting the quantitative variable into bins is to do, such that each bin has an approximately equal number of observations. To do so, we can use the `cut2()` function from them **Hmisc** R package [@Hmisc]. The number of bins is specified in the `g =` argument, and the function will divide the observations into the number of specified bins, such that each bin has an approximately equal number of observations.

```{r}
#| echo: true
gss24_ai |> 
  mutate(age_bins = cut2(age, g = 10)) |>
  group_by(age_bins) |>
  count(aidrive_comfort) |>
  mutate(probability = n / sum(n)) |>
  mutate(empirical_logit = log(probability/(1 - probability))) |>
  filter(aidrive_comfort == 1) 

```

We see the bins are more evenly distributed than using the previous method, but there is not an equal number in each bin. This is because the data set is imbalanced, as there are many more respondents in the data who are 18 - 27 years old versus 75 years and older. We can try different values for `g =` (minimum of 5), if we wish to make the bins more evenly distributed.

The plot of the empirical logit versus a quantitative predictor has the mean value within each bin on the $x$-axis and the empirical logit for the bin on the $y$-axis. In the code below, we use the `summarise()` function in the **dplyr** R package [@dplyr-2] to compute the mean age within each bin. We then join the mean ages to the empirical logit data computed above <!--# can you cross reference a code chunk?--> (saved as the object `emplogit_age`), and use the combined data to create the scatterplot.

```{r}
#| echo: false

emplogit_age <- gss24_ai |> 
  mutate(age_bins = cut(age, breaks = 10)) |>
  group_by(age_bins) |>
  count(aidrive_comfort) |>
  mutate(probability = n / sum(n)) |>
  mutate(empirical_logit = log(probability/(1 - probability))) |>
  filter(aidrive_comfort == 1)
```

```{r}
#| echo: true

# compute mean age for each bin
mean_age  <- gss24_ai |> 
  mutate(age_bins = cut(age, breaks = 10)) |> 
  group_by(age_bins) |>
  summarise(mean_age = mean(age))

# join the mean ages and create scatterplot
emplogit_age |> 
  left_join(mean_age, by = "age_bins") |>
  ggplot(aes(x = mean_age, y = empirical_logit)) +
  geom_point() +
  labs(x = "Mean age", 
       y = "Empirical logit of (aidrive_comfort = 1)") +
  theme_bw()

```

The **Stat2Data** R package [@Stat2Data] has built-in functions for making empirical logit plot utilizing the base R plotting functions (instead of **ggplot2**).

The `emplogitplot1()` function is used to create the empirical logit plot for the response versus a quantitative predictor variable. The argument `ngroups =` specifies the number of bins. The bins can be explicitly defined using the `breaks=` argument instead of `ngroups`.

The code for the empirical logit plot versus age using 10 bins is below.

```{r}
#| echo: true

emplogitplot1(aidrive_comfort ~ age, data = gss24_ai, ngroups = 10)
```

We can include the argument `out = TRUE` save the underlying data used to make the plot. Additionally, the argument `showplot = FALSE` will suppress the plot, if we are only interested in the underlying data.

```{r}
#| echo: true
emplogit_age_data <- emplogitplot1(aidrive_comfort ~ age, data = gss24_ai, 
                                   ngroups = 10, out = TRUE, showplot = FALSE)

emplogit_age_data
```

As we see from the output of underlying data, `emplogitplot1()` divides the quantitative variable into bins, such that the observations are approximately evenly distributed across bins. The result is very similar to the result from creating bins using `cut2()`. The underlying data in `emplogit_age_data` can be used to make the graph using the **ggplot2** functions, as shown below.

```{r}
#| echo: true
ggplot(emplogit_age_data, aes(x = XMean, y = Logit )) + 
  geom_point() + 
    labs(x = "Mean age", 
       y = "Empirical logit of (aidrive_comfort = 1)") +
  theme_bw()
```

## Summary

In this chapter we introduced logistic regression for data with a binary categorical response variable. We used probabilities and odds to describe the distribution of the response variable, and we used odds ratios to understand the relationship between the response and predictor variables. We introduced the form of the logistic regression model and interpreted the model coefficients in terms of the logit and odds. We used simulation-based and theory-based methods to draw conclusions about individual coefficients, and used model conditions to evaluate whether the assumptions for logistic regression hold in the data. We concluded by showing these elements of logistic regression analysis in R.

In @sec-ch-logistic-prediction, we will continue with logistic regression models and show how these models are used for prediction and classification. We will also present statistics to evaluate model fit and conduct model selection.
